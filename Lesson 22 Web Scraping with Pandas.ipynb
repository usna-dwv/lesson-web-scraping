{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2642ca0a-d7ea-4bb7-af25-e58a260b3a60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**SA234 &#x25aa; Data Wrangling and Visualization &#x25aa; Spring 2026**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f31bf-25e6-4c76-901b-0ed1cbc3e03e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Lesson 22. Web Scraping with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42698472-175c-416a-9269-eb4d9de74290",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396ddb41-d26d-40c8-84df-9930c6e0090e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- **Web scraping** is the process of collecting structured data from web pages in an automated fashion\n",
    "\n",
    "\n",
    "- In this lesson, we'll see how we can use some functionality built into Pandas to read tabular data from web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a895bbed-d1dc-4eaf-8e30-0fe460c49fd6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55542bc-e665-4ace-a29b-97470dd67a29",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reading data from the clipboard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b70d3c-96c9-426e-9b04-82e669d6193e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Let's start by importing Pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b05b1b8-f7f2-4002-b0b5-a538b888e4d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47df418-0c45-4fec-9d76-339f27a40a70",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- One easy way to read tabular data from a web page is to perform a slightly fancier version of copy-and-paste "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9412bbf2-9c6f-4e72-9b3c-5b39938c4975",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- `pd.read_clipboard()` reads the text in your clipboard and passes it to `pd.read_csv()` to create a DataFrame\n",
    "    - [Documentation for `pd.read_clipboard()`](https://pandas.pydata.org/docs/reference/api/pandas.read_clipboard.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b6c126-d755-4ff8-8e08-6f81cb28096a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- In this way, we can \"manually\" scrape data from a web page\n",
    "    - This method is good to use in pinch\n",
    "    - Be careful, though, since this method isn't easily automated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06b993-438f-4e0b-9500-c79d7955d291",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- As an example, let's take a look at the [Wikipedia page for Super Bowl LIV](https://en.wikipedia.org/wiki/Super_Bowl_LIV)\n",
    "\n",
    "\n",
    "- Highlight the \"Team-to-team comparison\" table in your browser, and copy it\n",
    "\n",
    "\n",
    "- Now let's use `pd.read_clipboard()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1621e6-ab26-4271-a982-a897139a240d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2faf0fd2-fb8e-49b4-a4f2-244f3740b278",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Looks good! üòé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9a439-23c2-4527-9928-638da552a0b7",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8911a402-6efc-49f6-9d70-36d18063c626",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Reading data from a webpage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c23d84-79a9-4175-90ef-6bbcd400b749",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Instead of using the clipboard, we can ask Pandas to look for all the tables in a web page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f334eb-6537-404a-8dd9-915951e3d9a8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- `pd.read_html()` reads any tables it finds in an HTML file into a *list of DataFrames*\n",
    "    - [Documentation for `pd.read_html()`](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103fe9a-e047-480d-abe8-58cd203259ae",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- For example, we can grab all the tables from the Wikipedia page on Super Bowl LIV like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0373904a-b9d0-49a5-b9d4-ffc302282f05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5241f46-b074-421c-a6bd-ab5b5447fd9b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- We can see how many tables Pandas found and converted to DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaeb9f0-b594-41ba-b3df-38170f42d8e8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9fd0045-3bcd-4580-a8d9-a81f3a471311",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- We can inspect each DataFrame to figure out which one we want\n",
    "\n",
    "\n",
    "- For example, it turns out the \"Team-to-team comparison\" table above is the item with index 7 in the list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b92850-126d-47bf-adc7-ece513203093",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d92f1e18-9e27-4973-97ac-036d0b25a95b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Sometimes, Pandas doesn't convert the table to a DataFrame so cleanly\n",
    "\n",
    "- For example, if we look at the \"Scoring summary\" table, which happens to be item with index 5 in the list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6bf94-f743-4c3b-affe-c1632baec4a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d5f3ad8-286c-4c4f-9f92-ca9c29cb2a6a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- All the information is there, but it's kind of a mess\n",
    "\n",
    "\n",
    "- Let's clean it up!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf74c85-a1a3-419f-b150-276fd17e3d04",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "1. First, let's remove rows 0, 1, 2, and 12\n",
    "    - In the past, we've used `.drop(columns=...)` to delete columns\n",
    "    - We can delete rows using `.drop(index=...)`\n",
    "    - [Documentation for `.drop()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8661e87d-3b19-4bbf-b2bd-63a677028b27",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "2. Let's rename the columns\n",
    "    - In the past, we've used `.rename(columns=...)` to rename a few columns at a time\n",
    "    - However, we want to rename all the columns, and there are many, so that's a bit cumbersome\n",
    "    - We can use `.set_axis(..., axis='columns')` to rename all the columns at once\n",
    "    - [Documentation for `.set_axis()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_axis.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ca96cf-ef70-448e-8c47-7ad33d01ce33",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "3. Let's reset the index after all our work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feccd6e-9c40-4303-a6e2-b34df5bf79f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5067df9f-85dc-4d19-a661-961e32d4b2db",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Much better! üëç\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7924540-741b-40a5-8cae-5319f69ace7b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d8392b-8f64-4c8c-8a35-3a75165fe3fb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## More advanced web scraping in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0146364-271d-4cc1-944f-23586b84cdc5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- This web scraping functionality built into Pandas can be quite useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2552f-590d-45f9-99da-cbef41f14216",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- However, if you have more demanding web scraping needs &ndash; especially for data that is not tabular &ndash; you may need to look elsewhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2672fc9e-600c-4bc6-aa17-ad051f741a87",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) is a Python library for pulling data out of HTML (and XML) files\n",
    "    - It is possibly the most popular Python library for these kinds of tasks, with many tutorials and guides available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e22b07-94ea-423f-9210-16e5b3db82be",
   "metadata": {},
   "source": [
    "<hr style=\"border-top: 2px solid gray; margin-top: 1px; margin-bottom: 1px\"></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238197d6-a9ea-408f-b695-f4bef064a7c2",
   "metadata": {},
   "source": [
    "## Notes and sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9e898a-88bd-4db9-b36c-f8edf915bd76",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "- Lesson inspired by [this article by Lynn Leifker](https://github.com/LBBL96/Pandas-Web-Scraping-Tutorial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
